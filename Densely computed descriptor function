require 'image'
require 'nn'

function poolin( entry, layer, c )
   local te, res
   local s = entry:size()
   res = torch.Tensor(c, c, s[1], s[2]/c, s[3]/c )
   for i=1,c do
      for j=1,c do
         if i==1 and j~=1 then
            te = torch.cat( entry:narrow(3,j,s[3]-j+1), entry:narrow(3,1,j-1), 3 )  
            res[i][j] = layer:forward( te )
         elseif i==1 and j==1 then
            res[i][j] = layer:forward( entry )
         elseif i~=1 and j==1 then
            te = torch.cat( entry:narrow(2,i,s[2]-i+1), entry:narrow(2,1,i-1), 2 )
            res[i][j] = layer:forward( te )
         else
            te = torch.cat( entry:narrow(2,i,s[2]-i+1), entry:narrow(2,1,i-1), 2 )
            te = torch.cat( te:narrow(3,j,s[3]-j+1), te:narrow(3,1,j-1), 3 ) 
            res[i][j] = layer:forward( te )
         end
      end
   end
   local result = torch.Tensor( s )
   for i=1,s[1] do
      for j=1,s[2] do
         for k=1,s[3] do
            result[i][j][k] = res[1+(j-1)%c][1+(k-1)%c][i][1+(j-1)/c][1+(k-1)/c]
         end
      end
   end
   return result
end

poolv = true
--Zero-padding version, to prevent convolutions from reducing the size of the images
--desc is the descriptor we wish to compute densely
--im is the image which descriptor we want to compute
--kernel is a table containing the sizes of the different kernels used for convolution for all the convolution layers present in the neural network
--pool is the size of the pooling regions used in the pooling layers.
--cuda is a boolean that should be true when the code is running with a gpu and false if not.
--poolv indicates whether we let the pooling layers change the image's size or not.
function denseDesc( desc, im, kernel, pool, cuda)
   if torch.type(desc)=='nn.Sequential' then
      i=1
      if im:size(1)==1 then
         local inter = im:clone()
         local kernelcount = 0
         local poolcount = 0
         while desc:get(i)~=nil do
            print(i)
            local layer = desc:get(i)
            i = i + 1
            if torch.type(layer)=='nn.SpatialConvolution' or torch.type(layer)=='nn.SpatialConvolutionMap' then
               kernelcount = kernelcount + 1
               --Adjusting the zero padding before doing the convolution
               local pl, pr, pt, pb
               if kernel[kernelcount]%2==1 then
                  pl = torch.floor(kernel[kernelcount]/2)
                  pr = torch.floor(kernel[kernelcount]/2)
               else
                  pl = kernel[kernelcount]/2-1
                  pr = kernel[kernelcount]/2
               end
               if kernel[kernelcount]%2==1 then
                  pt = torch.floor(kernel[kernelcount]/2)
                  pb = torch.floor(kernel[kernelcount]/2)
               else
                  pt = kernel[kernelcount]/2-1
                  pb = kernel[kernelcount]/2
               end
               inter = layer:forward( nn.SpatialZeroPadding( pl, pr, pt, pb ):forward( inter ) )
            elseif torch.type(layer)=='nn.SpatialMaxPooling' or torch.type(layer)=='nn.SpatialLPPooling' or torch.type(layer)=='nn.SpatialAveragePooling' or torch.type(layer)=='nn.SpatialFractionalMaxPooling' then
               print('pool')
               print(poolv)
               poolcount = poolcount + 1
               local a = pool[poolcount] - inter:size()[2]%pool[poolcount]
               local b = pool[poolcount] - inter:size()[3]%pool[poolcount]
               if cuda then
                  inter = image.scale( inter:float(), inter:size()[2]+a, inter:size()[3]+b ):cuda()
               else
                  inter = image.scale( inter, inter:size()[2]+a, inter:size()[3]+b )
               end
               if poolv==true then
                  inter = poolin( inter, layer, pool[poolcount] )
               else
                  inter = layer:forward( inter )
               end
            elseif torch.type(layer)=='nn.SpatialAdaptiveMaxPooling' then
               print("The adaptive max pooling layer doesn't allow the dense computation of the descriptor")
               error()
            elseif (torch.type(layer)=='nn.View' or torch.type(layer)=='nn.Reshape') and desc:get(i+1)==nil then
               print('All good')
            elseif (torch.type(layer)=='nn.View' or torch.type(layer)=='nn.Reshape') and desc:get(i+1)~=nil then
               print('The reshaping ruins the dense computation of the descriptor')
               error()
            else
               inter = layer:forward( inter )
            end
         end
         return inter
      else
         local table = {}
         for k=1,im:size(1) do
            table[k] = denseDesc( desc, im:narrow(1,k,1) , kernel, pool, cuda )
         end
         local s = torch.LongStorage(4)
         s[1] = im:size(1)
         for k=2,4 do s[k] = table[1]:size(k-1) end
         local result = torch.Tensor(s)
         if cuda then 
            result = result:cuda() 
         end
         for k=1,im:size(1) do
            result[k] = table[k]
         end
         return result
      end
   else
      print('Bad descriptor')
      error()
   end
end
